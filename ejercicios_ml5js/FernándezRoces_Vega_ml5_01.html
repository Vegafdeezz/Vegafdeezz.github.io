<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ML5 01 · Cámara + Detección</title>

  <!-- ml5.js (versión fija para evitar cambios de API) -->
  <script src="https://unpkg.com/ml5@0.12.2/dist/ml5.min.js"></script>

  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 16px; }
    #wrap { position: relative; width: min(720px, 100%); }
    video, canvas { width: 100%; height: auto; border-radius: 10px; }
    canvas { position: absolute; left: 0; top: 0; }
    button { padding: 10px 12px; font-size: 14px; cursor: pointer; }
    .row { display:flex; gap:12px; flex-wrap: wrap; align-items:center; margin-bottom: 10px; }
    .badge { display:inline-block; border:1px solid #ccc; border-radius:999px; padding: 3px 10px; }
  </style>
</head>

<body>
  <h1>ML5 01 · Cámara en móvil + detección</h1>

  <div class="row">
    <button id="btnStart">Iniciar cámara</button>
    <span id="status" class="badge">Estado: esperando…</span>
    <span id="best" class="badge">Mejor detección: —</span>
  </div>

  <div id="wrap">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>
  </div>

  <div>
   <h3> Explicación de cómo funciona el código</h3>
      <p> El objetivo de esta tarea es poder tener una camara en tiempo real en nuestra web.</p>
      <p>Primero subimos el ml5.js, para tener una biblioteca de IA y luego añadimos los elementos principales: video (para mostrar la cámara) y canvas (para dibujar encima).</p>
      <p>Añadimos variables al script: detector (guardará el modelo de detección) y running (indica si el sistema está detectando o no). Después de esto debemos crear una funcion para actualizar el texto del estado (function setStatus(t)).</p>
      <p>Para iniciar la cámara iniciamos la funcion initCamera(), esta se refleja en un boton, el cual es obligatorio ya que los navegadores no dejan activar las cámaras sin permiso por seguridad.<br>
      Cuando pulsamos el boton el programa le pide permiso de acceso a la cámara usando getUserMedia(). En móviles se intenta utilizar la cámara trasera. Una vez que la cámara se activa, el vídeo empieza a mostrar en directo lo que está viendo el teléfono.</p>
      <p>Después de encender la cámara el canvas se ajusta al tamaño real del vídeo. Si no se ajustara, los dibujos podrían aparecer descolocados.</p>
      <p>A continuación se carga el modelo de detección llamado COCO-SSD. Este modelo ya está entrenado para reconocer muchos objetos diferentes. Cuando termina de cargarse, el sistema empieza a analizar la imagen de la cámara continuamente y detectando objetos en un bucle</p>
      <p>Cada vez que encuentra algo, devuelve una lista de resultados con el nombre del objeto y el porcentaje de seguridad. Con esa información, el programa dibuja un rectángulo alrededor del objeto y escribe su etiqueta con la confianza.</p>
  </div>


  <script>
    const btnStart = document.getElementById("btnStart");
    const statusEl = document.getElementById("status");
    const bestEl = document.getElementById("best");

    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");

    let detector = null;
    let running = false;

    function setStatus(t) { statusEl.textContent = "Estado: " + t; }

    async function initCamera() {
      // En móvil, "environment" intenta usar la cámara trasera
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: { ideal: "environment" } },
        audio: false
      });

      video.srcObject = stream;

      await new Promise(res => video.onloadedmetadata = () => res());

      // Ajustar canvas al tamaño real del vídeo
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }

    function draw(detections) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.lineWidth = 3;
      ctx.font = "16px system-ui, Arial";

      for (const d of detections) {
        ctx.strokeRect(d.x, d.y, d.width, d.height);
        const label = `${d.label} (${Math.round(d.confidence * 100)}%)`;
        ctx.fillText(label, d.x + 6, Math.max(16, d.y + 16));
      }
    }

    function pickBest(detections) {
      if (!detections || detections.length === 0) return null;
      let best = detections[0];
      for (const d of detections) {
        if (d.confidence > best.confidence) best = d;
      }
      return best;
    }

    function loopDetect() {
      if (!running || !detector) return;

      detector.detect(video, (err, results) => {
        if (err) {
          console.error(err);
          setStatus("error en detección (ver consola)");
          running = false;
          return;
        }

        draw(results);

        const best = pickBest(results);
        bestEl.textContent = best
          ? `Mejor detección: ${best.label} (${Math.round(best.confidence * 100)}%)`
          : "Mejor detección: —";

        requestAnimationFrame(loopDetect);
      });
    }

    btnStart.addEventListener("click", async () => {
      try {
        btnStart.disabled = true;

        setStatus("iniciando cámara…");
        await initCamera();

        setStatus("cargando modelo COCO-SSD…");
        detector = await ml5.objectDetector("cocossd");

        setStatus("detectando…");
        running = true;
        loopDetect();

      } catch (e) {
        console.error(e);
        setStatus(`error: ${e.name} — ${e.message}`);
        btnStart.disabled = false;
      }
    });
  </script>
</body>
</html>
